{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if args.lang == 'de':\n",
    "    model_name = 'deepset/gbert-base'\n",
    "\n",
    "elif args.lang == 'ja':\n",
    "    model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "\n",
    "elif args.lang == 'ar':\n",
    "    model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "\n",
    "elif args.lang == 'es':\n",
    "    model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "\n",
    "elif args.lang == 'pt':\n",
    "    model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "\n",
    "elif args.lang == 'ru':\n",
    "    model_name = 'blinoff/roberta-base-russian-v0'\n",
    "\n",
    "elif args.lang == 'id':\n",
    "    model_name = 'cahya/bert-base-indonesian-1.5G'\n",
    "\n",
    "elif args.lang == 'zh':\n",
    "    model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "\n",
    "elif args.lang == 'multi-xlm':\n",
    "    model_name = 'xlm-mlm-100-1280'\n",
    "    \n",
    "elif args.lang == 'multi-bert':\n",
    "\n",
    "\n",
    "Dataset source: https://hatespeechdata.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import difflib\n",
    "import nltk\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset_builder, load_dataset, get_dataset_split_names, get_dataset_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spanish\n",
    "# dataset_name = \"Paul/hatecheck-spanish\"\n",
    "dataset_name = \"Paul/hatecheck-portuguese\"\n",
    "# dataset_name = \"Paul/hatecheck-german\"\n",
    "# dataset_name = \"Paul/hatecheck-italian\"\n",
    "# dataset_name = \"flax-sentence-embeddings/Gender_Bias_Evaluation_Set\"\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Paul--hatecheck-portuguese-beb1288febbedace\n",
      "Found cached dataset csv (C:/Users/cass/.cache/huggingface/datasets/Paul___csv/Paul--hatecheck-portuguese-beb1288febbedace/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['mhc_case_id', 'functionality', 'test_case', 'label_gold', 'target_ident', 'ref_case_id', 'ref_templ_id', 'templ_id', 'case_templ', 'gender_male', 'gender_female', 'label_annotated', 'label_annotated_maj', 'disagreement_in_case', 'disagreement_in_template'],\n",
       "    num_rows: 3691\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"test\")  #, split=\"test\"\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', 'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', 'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "    elif lang == 'pt':\n",
    "        idt_list = ['muçulmanos', 'judeus', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "    elif lang == 'fr': \n",
    "        idt_list = ['musulman', 'juif', 'juifs', 'blanc', 'islam', 'noirs', 'musulmans', 'femmes', 'blancs', 'gay', 'noir', 'démocat', 'islamique ', 'allah', 'juif', 'lesbienne', 'transgenre', 'race', 'marron', 'femme', 'mexicain', 'religion', 'homosexuel', 'homosexualité', 'africains']\n",
    "    elif lang == 'du': \n",
    "        idt_list = ['moslim', 'jood', 'joden', 'blank', 'islam', 'zwarten', 'moslims', 'vrouwen', 'blanken', 'homo', 'zwart', 'demokat', 'islamitisch ', 'allah', 'joods', 'lesbisch', 'transgender', 'ras', 'bruin', 'vrouw', 'mexicaans', 'religie', 'homoseksueel', 'homoseksualiteit', 'afrikanen']\n",
    "    elif lang == 'it': \n",
    "        idt_list = ['musulmano', 'ebreo', 'ebrei', 'bianco', 'islam', 'neri', 'musulmani', 'donne', 'bianchi', 'gay', 'neri', 'demogatti', 'islamici ', 'allah', 'ebrea', 'lesbica', 'transgender', 'razza', 'marrone', 'donna', 'messicana', 'religione', 'omosessuale', 'omosessualità', 'africani']\n",
    "    elif lang == 'zh': \n",
    "        idt_list = ['穆斯林', '犹太', '犹太人', '白人', '伊斯兰', '黑人', '女', '白人', '工党', '真主', '犹太教', '拉拉', '变性', '种族', '棕色', '墨西哥', '宗教', '同性', '同性恋', '非洲人']\n",
    "    elif lang == 'ar':\n",
    "        idt_list = [\"الله\" ,\"اليهود\" ,\"السحاقيات\" ,\"المتحولين جنسياً\" ,\"العرق\" ,\"البني\" ,\"المرأة\" ,\"المكسيكي\" ,\"الدين\" ,\"مثلي الجنس\" ,\"الشذوذ الجنسي\" ,\"الأفارقة\"]\n",
    "    return idt_list\n",
    "\n",
    "idt_list = get_idt(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = []\n",
    "nonhate = []\n",
    "for i in dataset:\n",
    "    if i['label_gold'] == 'hateful':\n",
    "        hate.append(i['test_case'])\n",
    "    else:\n",
    "        nonhate.append(i['test_case'])\n",
    "\n",
    "\n",
    "hate_idt = []\n",
    "hate_nonidt = []\n",
    "for i in hate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        hate_idt.append(i)\n",
    "    else:\n",
    "        hate_nonidt.append(i) # hate without idt / non hate with idt\n",
    "\n",
    "\n",
    "nonhate_idt = []\n",
    "nonhate_nonidt = []\n",
    "for i in nonhate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        nonhate_idt.append(i)\n",
    "    else:\n",
    "        nonhate_nonidt.append(i) # hate without idt / non hate with idt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/hate_nonidt.json\", 'w') as f:\n",
    "    json.dump(hate_nonidt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/nonhate_idt.json\", 'w') as f:\n",
    "    json.dump(nonhate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/nonhate_nonidt.json\", 'w') as f:\n",
    "    json.dump(nonhate_nonidt, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(lang):\n",
    "    if lang == 'de':\n",
    "        model_name = 'deepset/gbert-base' \n",
    "    elif lang == 'de-xlm':\n",
    "        model_name = 'xlm-roberta-large-finetuned-conll03-german'\n",
    "    elif lang == 'en':\n",
    "        model_name = 'bert-base-uncased'\n",
    "    elif lang == 'en-xlm':\n",
    "        model_name = 'xlm-mlm-ende-1024'\n",
    "    elif lang == 'ja': \n",
    "        model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "    elif lang == 'ar': # Arabic\n",
    "        model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "    elif lang == 'es': \n",
    "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "    elif lang == 'pt': \n",
    "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "    elif lang == 'ru': \n",
    "        model_name = 'blinoff/roberta-base-russian-v0'\n",
    "    elif lang == 'id':\n",
    "        model_name = 'cahya/bert-base-indonesian-1.5G'\n",
    "    elif lang == 'zh':\n",
    "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "    elif lang == 'multi-xlm':\n",
    "        model_name = 'xlm-mlm-100-1280'\n",
    "    elif lang == 'multi-bert':\n",
    "        model_name = 'bert-base-multilingual-uncased'\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', 'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', 'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "    elif lang == 'pt': \n",
    "        idt_list = ['muçulmanos', 'judeus', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "    return idt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aul(model, token_ids, log_softmax, attention):\n",
    "    '''\n",
    "    Given token ids of a sequence, return the averaged log probability of\n",
    "    unmasked sequence (AULA or AUL).\n",
    "    '''\n",
    "    output = model(token_ids)\n",
    "    logits = output.logits.squeeze(0)\n",
    "    log_probs = log_softmax(logits)\n",
    "    token_ids = token_ids.view(-1, 1).detach()\n",
    "    token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
    "    if attention:\n",
    "        attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
    "        averaged_attentions = torch.mean(attentions, 0)\n",
    "        averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
    "        token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
    "    sentence_log_prob = torch.mean(token_log_probs)\n",
    "    score = sentence_log_prob.item()\n",
    "\n",
    "    hidden_states = output.hidden_states[-1][:,1:-1]\n",
    "    hidden_state = torch.mean(hidden_states, 1).detach().cpu().numpy()\n",
    "\n",
    "    return score, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('en.json',)\n",
    "# data = json.load(f)\n",
    "\n",
    "# idt_rationale_list = []\n",
    "# idt_token_list = []\n",
    "\n",
    "# rationale_list = []\n",
    "# token_list = []\n",
    "\n",
    "# for i in data:\n",
    "#     total = []\n",
    "#     for annot in data[i]['annotators']:\n",
    "#         total += annot['target']\n",
    "#     if 'None' in total: # at least one people think it is not hate speech, only keep all 3 think it is hateful\n",
    "#         pass\n",
    "#     else:\n",
    "#         if len([each for each in idt_list if each.lower() in data[i]['post_tokens']])>0: # hate speech with idt           \n",
    "#             idt_token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             idt_rationale_list.append(data[i]['rationales'])\n",
    "#         else:\n",
    "#             token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             rationale_list.append(data[i]['rationales'])\n",
    "# f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to token id and start measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For Germany\n",
    "# df = pd.read_table('de.txt', sep='\t', lineterminator='\\n', header=None)\n",
    "# df.columns = ['text', 'binary', 'multi'] \n",
    "# df = df.loc[df['binary']=='OFFENSE']\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
