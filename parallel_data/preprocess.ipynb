{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cass/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import difflib\n",
    "import nltk\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset_builder, load_dataset, get_dataset_split_names, get_dataset_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spanish\n",
    "# dataset_name = \"Paul/hatecheck-spanish\"\n",
    "# dataset_name = \"Paul/hatecheck-portuguese\"\n",
    "# dataset_name = \"Paul/hatecheck-german\"\n",
    "# dataset_name = \"Paul/hatecheck-italian\"\n",
    "# dataset_name = \"flax-sentence-embeddings/Gender_Bias_Evaluation_Set\"\n",
    "\n",
    "dataset_name = \"piuba-bigdata/contextualized_hate_speech\"\n",
    "lang = 'es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/cass/.cache/huggingface/datasets/piuba-bigdata___parquet/piubamas--contextualized_hate_speech-c08e1901e40a0438/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 343726,\n",
       " 'title': 'Video: salió de la cárcel por el coronavirus y murió de un tiro el mismo día al festejar su libertad',\n",
       " 'text': '@usuario Uno menos',\n",
       " 'context_tweet': 'Video: salió de la cárcel por el coronavirus y murió de un tiro el mismo día al festejar su libertad https://t.co/UrJGRAdEvD',\n",
       " 'HATEFUL': 1,\n",
       " 'body': 'Un hombre de 46 años, que cumplía una condena en prisión y fue puesto en libertad por el coronavirus, murió el mismo día que dejó la cárcel baleado por un primo, durante los \"festejos\" por dejar la prisión.\\n\\nSari Salem Wardat, de 46 años, recibió un disparo desde atrás en un aparente accidente mientras caminaba hacia miembros de la familia y vecinos que se habían reunido para darle la bienvenida a su casa, en Jordania.\\n\\nUn video que circuló en las redes sociales \\u200bmuestra a Sari llegando a su casa en un auto azul rodeado de tiros de \"celebración\". El primo se acerca de inmediato a Sari, que sostiene una pistola y la apunta hacia el cielo.\\n\\nEl detenido liberado, al lado de la puerta del acompañante, mira a su primo quien \"festeja\" la liberación.\\n\\nMirá también Mirá también El increíble video de unos monos que se tiran a la pileta como Charly García\\n\\nEl arma parece trabarse dos veces antes de que el primo dispare siete tiros al aire mientras Sari camina hacia las personas reunidas en la calle. Luego, el arma se traba una vez más y allí el preso liberado recibe un tiro accidental en la cabeza.\\n\\nSari había estado cumpliendo una condena de ocho meses de prisión por portar un arma sin licencia y resistir el arresto, pero también se cree que era un traficante de drogas y un contrabandista. Fue puesto en libertad dos semanas antes del final de su condena como parte de las medidas gubernamentales de Jordania para prevenir la propagación del coronavirus.',\n",
       " 'CALLS': 0,\n",
       " 'WOMEN': 0,\n",
       " 'LGBTI': 0,\n",
       " 'RACISM': 0,\n",
       " 'CLASS': 0,\n",
       " 'POLITICS': 0,\n",
       " 'DISABLED': 0,\n",
       " 'APPEARANCE': 0,\n",
       " 'CRIMINAL': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"train\")  #, split=\"test\"\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', 'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', 'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "    elif lang == 'pt':\n",
    "        idt_list = ['muçulmanos', 'judeus', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "    elif lang == 'fr': \n",
    "        idt_list = ['musulman', 'juif', 'juifs', 'blanc', 'islam', 'noirs', 'musulmans', 'femmes', 'blancs', 'gay', 'noir', 'démocat', 'islamique ', 'allah', 'juif', 'lesbienne', 'transgenre', 'race', 'marron', 'femme', 'mexicain', 'religion', 'homosexuel', 'homosexualité', 'africains']\n",
    "    elif lang == 'du': \n",
    "        idt_list = ['moslim', 'jood', 'joden', 'blank', 'islam', 'zwarten', 'moslims', 'vrouwen', 'blanken', 'homo', 'zwart', 'demokat', 'islamitisch ', 'allah', 'joods', 'lesbisch', 'transgender', 'ras', 'bruin', 'vrouw', 'mexicaans', 'religie', 'homoseksueel', 'homoseksualiteit', 'afrikanen']\n",
    "    elif lang == 'it': \n",
    "        idt_list = ['musulmano', 'ebreo', 'ebrei', 'bianco', 'islam', 'neri', 'musulmani', 'donne', 'bianchi', 'gay', 'neri', 'demogatti', 'islamici ', 'allah', 'ebrea', 'lesbica', 'transgender', 'razza', 'marrone', 'donna', 'messicana', 'religione', 'omosessuale', 'omosessualità', 'africani']\n",
    "    elif lang == 'zh': \n",
    "        idt_list = ['穆斯林', '犹太', '犹太人', '白人', '伊斯兰', '黑人', '女', '白人', '工党', '真主', '犹太教', '拉拉', '变性', '种族', '棕色', '墨西哥', '宗教', '同性', '同性恋', '非洲人']\n",
    "    elif lang == 'ar':\n",
    "        idt_list = [\"الله\" ,\"اليهود\" ,\"السحاقيات\" ,\"المتحولين جنسياً\" ,\"العرق\" ,\"البني\" ,\"المرأة\" ,\"المكسيكي\" ,\"الدين\" ,\"مثلي الجنس\" ,\"الشذوذ الجنسي\" ,\"الأفارقة\"]\n",
    "    return idt_list\n",
    "\n",
    "idt_list = get_idt(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = []\n",
    "nonhate = []\n",
    "for i in dataset:\n",
    "    if i['HATEFUL'] == 1:\n",
    "        hate.append(i['text'])\n",
    "    else:\n",
    "        nonhate.append(i['text'])\n",
    "\n",
    "\n",
    "hate_idt = []\n",
    "hate_nonidt = []\n",
    "for i in hate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        hate_idt.append(i)\n",
    "    else:\n",
    "        hate_nonidt.append(i) # hate without idt / non hate with idt\n",
    "\n",
    "\n",
    "nonhate_idt = []\n",
    "nonhate_nonidt = []\n",
    "for i in nonhate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        nonhate_idt.append(i)\n",
    "    else:\n",
    "        nonhate_nonidt.append(i) # hate without idt / non hate with idt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = []\n",
    "nonhate = []\n",
    "for i in dataset:\n",
    "    if i['label_gold'] == 'hateful':\n",
    "        hate.append(i['test_case'])\n",
    "    else:\n",
    "        nonhate.append(i['test_case'])\n",
    "\n",
    "\n",
    "hate_idt = []\n",
    "hate_nonidt = []\n",
    "for i in hate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        hate_idt.append(i)\n",
    "    else:\n",
    "        hate_nonidt.append(i) # hate without idt / non hate with idt\n",
    "\n",
    "\n",
    "nonhate_idt = []\n",
    "nonhate_nonidt = []\n",
    "for i in nonhate:\n",
    "    if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "        nonhate_idt.append(i)\n",
    "    else:\n",
    "        nonhate_nonidt.append(i) # hate without idt / non hate with idt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"./hateB/{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"./hateB/{lang}/hate_nonidt.json\", 'w') as f:\n",
    "    json.dump(hate_nonidt, f, indent=4) \n",
    "\n",
    "with open(f\"./hateB/{lang}/nonhate_idt.json\", 'w') as f:\n",
    "    json.dump(nonhate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"./hateB/{lang}/nonhate_nonidt.json\", 'w') as f:\n",
    "    json.dump(nonhate_nonidt, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/hate_nonidt.json\", 'w') as f:\n",
    "    json.dump(hate_nonidt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/nonhate_idt.json\", 'w') as f:\n",
    "    json.dump(nonhate_idt, f, indent=4) \n",
    "\n",
    "with open(f\"{lang}/nonhate_nonidt.json\", 'w') as f:\n",
    "    json.dump(nonhate_nonidt, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(lang):\n",
    "    if lang == 'de':\n",
    "        model_name = 'deepset/gbert-base' \n",
    "    elif lang == 'de-xlm':\n",
    "        model_name = 'xlm-roberta-large-finetuned-conll03-german'\n",
    "    elif lang == 'en':\n",
    "        model_name = 'bert-base-uncased'\n",
    "    elif lang == 'en-xlm':\n",
    "        model_name = 'xlm-mlm-ende-1024'\n",
    "    elif lang == 'ja': \n",
    "        model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "    elif lang == 'ar': # Arabic\n",
    "        model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "    elif lang == 'es': \n",
    "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "    elif lang == 'pt': \n",
    "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "    elif lang == 'ru': \n",
    "        model_name = 'blinoff/roberta-base-russian-v0'\n",
    "    elif lang == 'id':\n",
    "        model_name = 'cahya/bert-base-indonesian-1.5G'\n",
    "    elif lang == 'zh':\n",
    "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "    elif lang == 'multi-xlm':\n",
    "        model_name = 'xlm-mlm-100-1280'\n",
    "    elif lang == 'multi-bert':\n",
    "        model_name = 'bert-base-multilingual-uncased'\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', 'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', 'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "    elif lang == 'pt': \n",
    "        idt_list = ['muçulmanos', 'judeus', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "    return idt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aul(model, token_ids, log_softmax, attention):\n",
    "    '''\n",
    "    Given token ids of a sequence, return the averaged log probability of\n",
    "    unmasked sequence (AULA or AUL).\n",
    "    '''\n",
    "    output = model(token_ids)\n",
    "    logits = output.logits.squeeze(0)\n",
    "    log_probs = log_softmax(logits)\n",
    "    token_ids = token_ids.view(-1, 1).detach()\n",
    "    token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
    "    if attention:\n",
    "        attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
    "        averaged_attentions = torch.mean(attentions, 0)\n",
    "        averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
    "        token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
    "    sentence_log_prob = torch.mean(token_log_probs)\n",
    "    score = sentence_log_prob.item()\n",
    "\n",
    "    hidden_states = output.hidden_states[-1][:,1:-1]\n",
    "    hidden_state = torch.mean(hidden_states, 1).detach().cpu().numpy()\n",
    "\n",
    "    return score, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('en.json',)\n",
    "# data = json.load(f)\n",
    "\n",
    "# idt_rationale_list = []\n",
    "# idt_token_list = []\n",
    "\n",
    "# rationale_list = []\n",
    "# token_list = []\n",
    "\n",
    "# for i in data:\n",
    "#     total = []\n",
    "#     for annot in data[i]['annotators']:\n",
    "#         total += annot['target']\n",
    "#     if 'None' in total: # at least one people think it is not hate speech, only keep all 3 think it is hateful\n",
    "#         pass\n",
    "#     else:\n",
    "#         if len([each for each in idt_list if each.lower() in data[i]['post_tokens']])>0: # hate speech with idt           \n",
    "#             idt_token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             idt_rationale_list.append(data[i]['rationales'])\n",
    "#         else:\n",
    "#             token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             rationale_list.append(data[i]['rationales'])\n",
    "# f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to token id and start measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For Germany\n",
    "# df = pd.read_table('de.txt', sep='\t', lineterminator='\\n', header=None)\n",
    "# df.columns = ['text', 'binary', 'multi'] \n",
    "# df = df.loc[df['binary']=='OFFENSE']\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
