{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "import difflib\n",
    "import nltk\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from datasets import load_dataset_builder, load_dataset, get_dataset_split_names, get_dataset_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Paul/hatecheck\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-spanish\"\n",
    "# dataset_name = \"piuba-bigdata/contextualized_hate_speech\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-portuguese\"\n",
    "# dataset_name = \"hate_speech_portuguese\"\n",
    "# dataset_name = \"Paul/hatecheck-german\"\n",
    "# dataset_name = \"Paul/hatecheck-italian\"\n",
    "# dataset_name = \"flax-sentence-embeddings/Gender_Bias_Evaluation_Set\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-arabic\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-french\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-mandarin\"\n",
    "\n",
    "# dataset_name = \"Paul/hatecheck-dutch\"\n",
    "# dataset_name = \"Paul/hatecheck-polish\"\n",
    "# dataset_name = \"Paul/hatecheck-hindi\"\n",
    "\n",
    "lang = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/cass/.cache/huggingface/datasets/Paul___csv/Paul--hatecheck-de74109e77bfb6c3/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "Creating CSV from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 96.52ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "652140"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_name, split=\"test\")  #, split=\"test\"\n",
    "dataset[0]\n",
    "dataset.to_csv(f'./hate/{lang}/identity_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_idt = []\n",
    "nonhate_idt = []\n",
    "\n",
    "for i in dataset:\n",
    "    if i['label_gold'] == 'hateful':\n",
    "        if i['target_ident'] != None:\n",
    "            hate_idt.append(i['test_case'])\n",
    "    elif i['label_gold'] == 'non-hateful':\n",
    "        if i['target_ident'] != None:\n",
    "            nonhate_idt.append(i['test_case'])\n",
    "    else:\n",
    "        print(i)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "path = f\"./hate/{lang}/\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "\n",
    "with open(f\"./hate/{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "with open(f\"./hate/{lang}/nonhate_idt.json\", 'w') as f:\n",
    "    json.dump(nonhate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "quit()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate women. ',\n",
       " 'I hate trans people. ',\n",
       " 'I hate trans people. ',\n",
       " 'I hate gay people. ',\n",
       " 'I hate black people. ',\n",
       " 'I hate disabled people. ',\n",
       " 'I hate Muslims. ',\n",
       " 'I hate immigrants. ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idt_list = ['trans', 'gay', 'disabili', 'musulmani', 'immigrati', 'donne', 'neri', 'persone di colore']\n",
    "# idt_list = ['negro', 'gay', 'trans', 'indígena', 'judíos', 'discapacitados', 'mujeres']\n",
    "# idt_list = ['mulheres', 'negros', 'gays', 'pessoas', 'trans', 'indígenas', 'judeus', 'deficientes']\n",
    "idt_list = ['女人', '跨性别者', '同性恋', '黑人', '穆斯林', '外国人']\n",
    "\n",
    "\n",
    "logging.info(idt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(list(zip(idt_list, sentence_example)),\n",
    "#                columns =['Identity terms', 'Sentences'])\n",
    "# df.to_csv(f'./hate/{lang}/identity_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['women', 'trans', 'gay', 'black', 'disabled', 'Muslims', 'immigrants']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hate_idt = []\n",
    "hate_nonidt = []\n",
    "\n",
    "for i in dataset:\n",
    "    if i['label_gold'] == 'hateful':\n",
    "        sentence = i['test_case']\n",
    "        if any(word.lower() in sentence.split() for word in idt_list):\n",
    "            hate_idt.append(sentence)\n",
    "        else:\n",
    "            hate_nonidt.append(sentence)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "with open(f\"./hate/{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "with open(f\"./hate/{lang}/hate_nonidt.json\", 'w') as f:\n",
    "    json.dump(hate_nonidt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"./hate/{lang}/hate_idt.json\", 'w') as f:\n",
    "    json.dump(hate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "with open(f\"./hate/{lang}/hate_nonidt.json\", 'w') as f:\n",
    "    json.dump(hate_nonidt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "with open(f\"./hate/{lang}/nonhate_idt.json\", 'w') as f:\n",
    "    json.dump(nonhate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "with open(f\"./hate/{lang}/nonhate_nonidt.json\", 'w') as f:\n",
    "    json.dump(nonhate_nonidt, f, indent=4, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(f\"./hateB/{lang}/hate_idt.json\", 'w') as f:\n",
    "#     json.dump(hate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "# with open(f\"./hateB/{lang}/hate_nonidt.json\", 'w') as f:\n",
    "#     json.dump(hate_nonidt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "# with open(f\"./hateB/{lang}/nonhate_idt.json\", 'w') as f:\n",
    "#     json.dump(nonhate_idt, f, indent=4, ensure_ascii=False) \n",
    "\n",
    "# with open(f\"./hateB/{lang}/nonhate_nonidt.json\", 'w') as f:\n",
    "#     json.dump(nonhate_nonidt, f, indent=4, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hate = []\n",
    "# nonhate = []\n",
    "# for i in dataset:\n",
    "#     if i['label'] == 1:\n",
    "#         hate.append(i['text'])\n",
    "#     else:\n",
    "#         nonhate.append(i['text'])\n",
    "\n",
    "\n",
    "# hate_idt = []\n",
    "# hate_nonidt = []\n",
    "# for i in hate:\n",
    "#     if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "#         hate_idt.append(i)\n",
    "#     else:\n",
    "#         hate_nonidt.append(i) # hate without idt / non hate with idt\n",
    "\n",
    "\n",
    "# nonhate_idt = []\n",
    "# nonhate_nonidt = []\n",
    "# for i in nonhate:\n",
    "#     if len([each for each in idt_list if each.lower() in i.split()])>0: # hate speech with idt\n",
    "#         nonhate_idt.append(i)\n",
    "#     else:\n",
    "#         nonhate_nonidt.append(i) # hate without idt / non hate with idt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "        idt_list = idt_list + [\"Frauen\",  \"Transmenschen\", \"Schwule\",  \"Schwarze\",  \"Behinderte\",\"Juden\",\"Flüchtlinge\"]\n",
    "        idt_list = list(set(idt_list))\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', \n",
    "                    'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', \n",
    "                    'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "        \n",
    "    elif lang == 'pt':\n",
    "        idt_list = ['muçulmanos', 'judeu', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "        idt_list = idt_list + ['muçulmano', 'judeu', 'judeus', 'branco', 'islã', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democrata', 'islâmico ', 'alá', 'judeu', 'lésbica', 'transgênero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "        idt_list = list(set(idt_list))\n",
    "        \n",
    "    elif lang == 'fr': \n",
    "        idt_list = ['musulman', 'juif', 'juifs', 'blanc', 'islam', 'noirs', 'musulmans', 'femmes', 'blancs', 'gay', 'noir', 'démocat', 'islamique ', 'allah', 'juif', 'lesbienne', 'transgenre', 'race', 'marron', 'femme', 'mexicain', 'religion', 'homosexuel', 'homosexualité', 'africains']\n",
    "    elif lang == 'du': \n",
    "        idt_list = ['moslim', 'jood', 'joden', 'blank', 'islam', 'zwarten', 'moslims', 'vrouwen', 'blanken', 'homo', 'zwart', 'demokat', 'islamitisch ', 'allah', 'joods', 'lesbisch', 'transgender', 'ras', 'bruin', 'vrouw', 'mexicaans', 'religie', 'homoseksueel', 'homoseksualiteit', 'afrikanen']\n",
    "    elif lang == 'it': \n",
    "        idt_list = ['musulmano', 'ebreo', 'ebrei', 'bianco', 'islam', 'neri', 'musulmani', 'donne', 'bianchi', 'gay', 'neri', 'demogatti', 'islamici ', 'allah', 'ebrea', 'lesbica', 'transgender', 'razza', 'marrone', 'donna', 'messicana', 'religione', 'omosessuale', 'omosessualità', 'africani']\n",
    "    elif lang == 'zh': \n",
    "        idt_list = ['穆斯林', '犹太', '犹太人', '白人', '伊斯兰', '黑人', '女', '白人', '工党', '真主', '犹太教', '拉拉', '变性', '种族', '棕色', '墨西哥', '宗教', '同性', '同性恋', '非洲人']\n",
    "    elif lang == 'ar':\n",
    "        idt_list = [\"الله\" ,\"اليهود\" ,\"السحاقيات\" ,\"المتحولين جنسياً\" ,\"العرق\" ,\"البني\" ,\"المرأة\" ,\"المكسيكي\" ,\"الدين\" ,\"مثلي الجنس\" ,\"الشذوذ الجنسي\" ,\"الأفارقة\"]\n",
    "    elif lang == 'hi':\n",
    "        idt_list = ['मुस्लिम', 'यहूदी', 'यहूदी', 'श्वेत', 'इस्लाम', 'अश्वेत', 'मुस्लिम', 'महिलाएं', 'गोरे', 'समलैंगिक', 'काला', 'डेमोकैट', 'इस्लामिक', 'अल्लाह', 'यहूदी', 'लेस्बियन', 'ट्रांसजेंडर', 'जाति', 'भूरा', 'महिला', 'मैक्सिकन', 'धर्म', 'समलैंगिक', 'समलैंगिकता', 'अफ्रीकी']\n",
    "    \n",
    "    return idt_list\n",
    "\n",
    "idt_list = get_idt(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(lang):\n",
    "    if lang == 'de':\n",
    "        model_name = 'deepset/gbert-base' \n",
    "    elif lang == 'de-xlm':\n",
    "        model_name = 'xlm-roberta-large-finetuned-conll03-german'\n",
    "    elif lang == 'en':\n",
    "        model_name = 'bert-base-uncased'\n",
    "    elif lang == 'en-xlm':\n",
    "        model_name = 'xlm-mlm-ende-1024'\n",
    "    elif lang == 'ja': \n",
    "        model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "    elif lang == 'ar': # Arabic\n",
    "        model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "    elif lang == 'es': \n",
    "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "    elif lang == 'pt': \n",
    "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "    elif lang == 'ru': \n",
    "        model_name = 'blinoff/roberta-base-russian-v0'\n",
    "    elif lang == 'id':\n",
    "        model_name = 'cahya/bert-base-indonesian-1.5G'\n",
    "    elif lang == 'zh':\n",
    "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "    elif lang == 'multi-xlm':\n",
    "        model_name = 'xlm-mlm-100-1280'\n",
    "    elif lang == 'multi-bert':\n",
    "        model_name = 'bert-base-multilingual-uncased'\n",
    "    return model_name\n",
    "\n",
    "\n",
    "def get_idt(lang):\n",
    "    if lang == 'de':\n",
    "        idt_list = [\"Muslime\", \"Juden\", \"Juden\", \"Weiße\", \"Islam\", \"Schwarze\", \"Muslime\", \"Frauen\", \"Weiße\", \"Schwule\", \"Schwarze\", \"Democat\", \"Islamisch\", \"Allah\", \"Jüdisch\", \"Lesbe\", \"Transgender\", \"Rasse\", \"Braun\", \"Frau\", \"Mexikaner\", \"Religion\", \"Homosexuell\", \"Homosexualität\", \"Afrikaner\"]\n",
    "    elif lang == 'en':\n",
    "        idt_list = ['muslim','jew', 'jews', 'white', 'islam', 'blacks', 'muslims', 'women', 'whites', 'gay', 'black', 'democat', 'islamic', 'allah', 'jewish','lesbian', 'transgender', 'race', 'brown', 'woman', 'mexican', 'religion', 'homosexual', 'homosexuality', 'africans']\n",
    "    elif lang == 'ja': \n",
    "        idt_list = ['イスラム教徒','ユダヤ人', 'ユダヤ人', '白人', 'イスラム教', '黒人', 'イスラム教徒', '女性', '白人', 'ゲイ', '黒人', 'デモキャット', 'イスラム教', 'アッラー', 'ユダヤ人', 'レズビアン', 'トランスジェンダー', '人種', '茶色', '女性', 'メキシコ人', '宗教', '同性愛者', '同性愛', 'アフリカ人']\n",
    "    elif lang == 'es': \n",
    "        idt_list = ['Musulmán', 'judío', 'judíos', 'blanco', 'islam', 'negros', 'musulmanes', 'mujeres', 'blancos', 'gay', 'negro', 'democat', 'islámico', 'Alá', 'judío', 'lesbiana', 'transgénero', 'raza', 'marrón', 'mujer', 'mexicano', 'religión', 'homosexual', 'homosexualidad', 'africanos']\n",
    "    elif lang == 'pt': \n",
    "        idt_list = ['muçulmanos', 'judeus', 'judeus', 'brancos', 'islâmicos', 'negros', 'muçulmanos', 'mulheres', 'brancos', 'gay', 'negro', 'democat', 'islâmico', 'allah', 'judeu', 'lésbicas', 'transgénero', 'raça', 'pardo', 'mulher', 'mexicano', 'religião', 'homossexual', 'homossexualidade', 'africanos']\n",
    "    return idt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aul(model, token_ids, log_softmax, attention):\n",
    "    '''\n",
    "    Given token ids of a sequence, return the averaged log probability of\n",
    "    unmasked sequence (AULA or AUL).\n",
    "    '''\n",
    "    output = model(token_ids)\n",
    "    logits = output.logits.squeeze(0)\n",
    "    log_probs = log_softmax(logits)\n",
    "    token_ids = token_ids.view(-1, 1).detach()\n",
    "    token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
    "    if attention:\n",
    "        attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
    "        averaged_attentions = torch.mean(attentions, 0)\n",
    "        averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
    "        token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
    "    sentence_log_prob = torch.mean(token_log_probs)\n",
    "    score = sentence_log_prob.item()\n",
    "\n",
    "    hidden_states = output.hidden_states[-1][:,1:-1]\n",
    "    hidden_state = torch.mean(hidden_states, 1).detach().cpu().numpy()\n",
    "\n",
    "    return score, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('en.json',)\n",
    "# data = json.load(f)\n",
    "\n",
    "# idt_rationale_list = []\n",
    "# idt_token_list = []\n",
    "\n",
    "# rationale_list = []\n",
    "# token_list = []\n",
    "\n",
    "# for i in data:\n",
    "#     total = []\n",
    "#     for annot in data[i]['annotators']:\n",
    "#         total += annot['target']\n",
    "#     if 'None' in total: # at least one people think it is not hate speech, only keep all 3 think it is hateful\n",
    "#         pass\n",
    "#     else:\n",
    "#         if len([each for each in idt_list if each.lower() in data[i]['post_tokens']])>0: # hate speech with idt           \n",
    "#             idt_token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             idt_rationale_list.append(data[i]['rationales'])\n",
    "#         else:\n",
    "#             token_list.append(' '.join(data[i]['post_tokens']))\n",
    "#             rationale_list.append(data[i]['rationales'])\n",
    "# f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to token id and start measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #For Germany\n",
    "# df = pd.read_table('de.txt', sep='\t', lineterminator='\\n', header=None)\n",
    "# df.columns = ['text', 'binary', 'multi'] \n",
    "# df = df.loc[df['binary']=='OFFENSE']\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5146f85bd0a5fa137f3aeb74a211d34c7fa6396ae5be3dd6eb960587644ed0a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
