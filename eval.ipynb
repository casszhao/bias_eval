{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import difflib\n",
    "import nltk\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import MeCab\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--lang', type=str, #required=True,\n",
    "                        choices=['en', 'de', 'ja', 'ar', 'es', 'pt', 'ru', 'id', 'zh'],\n",
    "                        help='Path to evaluation dataset.',\n",
    "                        default='de')\n",
    "    parser.add_argument('--method', type=str, #required=True,\n",
    "                        choices=['aula', 'aul'],\n",
    "                        default='aula')\n",
    "    parser.add_argument('--corpus', type=str, #required=True,\n",
    "                        choices=['ted', 'news'],\n",
    "                        default='ted')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_and_model(args):\n",
    "    '''\n",
    "    Load tokenizer and model to evaluate.\n",
    "    '''\n",
    "    if args.lang == 'de':\n",
    "        model_name = 'deepset/gbert-base'\n",
    "    elif args.lang == 'ja':\n",
    "        model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "    elif args.lang == 'ar':\n",
    "        model_name = 'aubmindlab/bert-base-arabertv02'\n",
    "    elif args.lang == 'es':\n",
    "        model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "    elif args.lang == 'pt':\n",
    "        model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "    elif args.lang == 'ru':\n",
    "        model_name = 'blinoff/roberta-base-russian-v0'\n",
    "    elif args.lang == 'id':\n",
    "        model_name = 'cahya/bert-base-indonesian-1.5G'\n",
    "    elif args.lang == 'zh':\n",
    "        model_name = 'hfl/chinese-bert-wwm-ext'\n",
    "    elif args.lang == 'multi-xlm':\n",
    "        model_name = 'xlm-mlm-100-1280'\n",
    "    elif args.lang == 'multi-bert':\n",
    "        model_name = 'bert-base-multilingual-uncased'\n",
    "\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name,\n",
    "                                                 output_hidden_states=True,\n",
    "                                                 output_attentions=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    model = model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.to('cuda')\n",
    "\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aul(model, token_ids, log_softmax, attention):\n",
    "    '''\n",
    "    Given token ids of a sequence, return the averaged log probability of\n",
    "    unmasked sequence (AULA or AUL).\n",
    "    '''\n",
    "    output = model(token_ids)\n",
    "    logits = output.logits.squeeze(0)\n",
    "    log_probs = log_softmax(logits)\n",
    "    token_ids = token_ids.view(-1, 1).detach()\n",
    "    token_log_probs = log_probs.gather(1, token_ids)[1:-1]\n",
    "    if attention:\n",
    "        attentions = torch.mean(torch.cat(output.attentions, 0), 0)\n",
    "        averaged_attentions = torch.mean(attentions, 0)\n",
    "        averaged_token_attentions = torch.mean(averaged_attentions, 0)\n",
    "        token_log_probs = token_log_probs.squeeze(1) * averaged_token_attentions[1:-1]\n",
    "    sentence_log_prob = torch.mean(token_log_probs)\n",
    "    score = sentence_log_prob.item()\n",
    "\n",
    "    hidden_states = output.hidden_states[-1][:,1:-1]\n",
    "    hidden_state = torch.mean(hidden_states, 1).detach().cpu().numpy()\n",
    "\n",
    "    return score, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    '''\n",
    "    Evaluate the bias in masked language models.\n",
    "    '''\n",
    "    tokenizer, model = load_tokenizer_and_model(args)\n",
    "    total_score = 0\n",
    "    stereo_score = 0\n",
    "    corpus = args.corpus\n",
    "    lang = args.lang\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "    mask_id = tokenizer.mask_token_id\n",
    "    log_softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "    female_inputs = pickle.load(open(f'parallel_data/{corpus}/{lang}_f.bin', 'rb'))\n",
    "    male_inputs = pickle.load(open(f'parallel_data/{corpus}/{lang}_m.bin', 'rb'))\n",
    "\n",
    "    attention = True if args.method == 'aula' else False\n",
    "\n",
    "    female_scores = []\n",
    "    male_scores = []\n",
    "    female_embes = []\n",
    "    male_embes = []\n",
    "\n",
    "    for female_tokens in female_inputs:\n",
    "        with torch.no_grad():\n",
    "            female_score, female_hidden_state = calculate_aul(model, female_tokens, log_softmax, attention)\n",
    "            female_scores.append(female_score)\n",
    "            female_embes.append(female_hidden_state)\n",
    "\n",
    "    for male_tokens in male_inputs:\n",
    "        with torch.no_grad():\n",
    "            male_score, male_hidden_state = calculate_aul(model, male_tokens, log_softmax, attention)\n",
    "            male_scores.append(male_score)\n",
    "            male_embes.append(male_hidden_state)\n",
    "\n",
    "    female_scores = np.array(female_scores)\n",
    "    female_scores = female_scores.reshape([-1, 1])\n",
    "    male_scores = np.array(male_scores)\n",
    "    male_scores = male_scores.reshape([1, -1])\n",
    "    bias_scores = male_scores > female_scores\n",
    "\n",
    "    female_embes = np.concatenate(female_embes)\n",
    "    male_embes = np.concatenate(male_embes)\n",
    "    weights = cos_sim(female_embes, male_embes.T)\n",
    "\n",
    "    weighted_bias_scores = bias_scores * weights\n",
    "    bias_score = np.sum(weighted_bias_scores) / np.sum(weights)\n",
    "    print('bias score (emb):', round(bias_score * 100, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--lang {en,de,ja,ar,es,pt,ru,id,zh}]\n",
      "                             [--method {aula,aul}] [--corpus {ted,news}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"7fa8c06a-bf4b-43e2-913e-86198992c715\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=c:\\Users\\cass\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-27484I9CRpIFh9n3c.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    main(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1436620147cb4a09ac227e74bcc7126081051218b3943a1b25bc49e7138a7a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
